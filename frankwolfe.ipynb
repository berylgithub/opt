{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import pylab as plt\n",
    "from sklearn import datasets\n",
    "from scipy.optimize import linprog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity of solution: 0.11%\n"
     ]
    }
   ],
   "source": [
    "'''from Fabian Pedregosa'''\n",
    "def FW(alpha, max_iter=200, tol=1e-8):\n",
    "    # .. initial estimate, could be any feasible point ..\n",
    "    x_t = sparse.dok_matrix((n_features, 1))\n",
    "    trace = []  # to keep track of the gap\n",
    "\n",
    "    # .. some quantities can be precomputed ..\n",
    "    Atb = A.T.dot(b)\n",
    "    for it in range(max_iter):\n",
    "        # .. compute gradient. Slightly more involved than usual because ..\n",
    "        # .. of the use of sparse matrices ..\n",
    "        Ax = x_t.T.dot(A.T).ravel()\n",
    "        grad = (A.T.dot(Ax) - Atb)\n",
    "        # .. the LMO results in a vector that is zero everywhere except for ..\n",
    "        # .. a single index. Of this vector we only store its index and magnitude ..\n",
    "        idx_oracle = np.argmax(np.abs(grad))\n",
    "        mag_oracle = alpha * np.sign(-grad[idx_oracle])\n",
    "        g_t = x_t.T.dot(grad).ravel() - grad[idx_oracle] * mag_oracle\n",
    "        trace.append(g_t)\n",
    "        if g_t <= tol:\n",
    "            break\n",
    "        q_t = A[:, idx_oracle] * mag_oracle - Ax\n",
    "        step_size = min(q_t.dot(b - Ax) / q_t.dot(q_t), 1.)\n",
    "        x_t = (1. - step_size) * x_t\n",
    "        x_t[idx_oracle] = x_t[idx_oracle] + step_size * mag_oracle\n",
    "    return x_t, np.array(trace)\n",
    "\n",
    "n_samples, n_features = 1000, 10000\n",
    "A, b = datasets.make_regression(n_samples, n_features)\n",
    "# .. plot evolution of FW gap ..\n",
    "sol, trace = FW(.5 * n_features)\n",
    "plt.plot(trace)\n",
    "plt.yscale('log')\n",
    "plt.xlabel('Number of iterations')\n",
    "plt.ylabel('FW gap')\n",
    "plt.title('FW on a Lasso problem')\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "sparsity = np.mean(sol.toarray().ravel() != 0)\n",
    "print('Sparsity of solution: %s%%' % (sparsity * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1428571428571428"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "8/7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     con: array([], dtype=float64)\n",
      "     fun: -11.428571428571427\n",
      " message: 'Optimization terminated successfully.'\n",
      "     nit: 2\n",
      "   slack: array([0.0000000e+00, 4.4408921e-16])\n",
      "  status: 0\n",
      " success: True\n",
      "       x: array([-1.14285714,  2.57142857])\n",
      "11.428571428571427\n"
     ]
    }
   ],
   "source": [
    "'''Linear Programming'''\n",
    "# f(x0,x1) = -x0 + 4x1\n",
    "f = lambda x: -x[0] + 4*x[1]\n",
    "c = np.array([-1, 4])\n",
    "A = [[-3, 1], [1, 2]]\n",
    "b = [6, 4]\n",
    "\n",
    "#A = None\n",
    "#b = None\n",
    "\n",
    "x0_bounds = (None, None)\n",
    "x1_bounds = (-3, None)\n",
    "res = linprog(-c, A_ub=A, b_ub=b, bounds=[x0_bounds, x1_bounds]) #there is also A_eq which is Ax = b constraints\n",
    "print(res)\n",
    "print(f(res[\"x\"]))\n",
    "#print(linear_program_oracle(c, A, b, [(None, None), (-3, None)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KWSA [-32.  -8.]\n",
      "RDSA [-19.20383889  33.21175151]\n",
      "IRDSA [-47.881254   -46.42896504]\n",
      "KWSA [0. 0.]\n",
      "RDSA [0. 0.]\n",
      "IRDSA [0. 0.]\n"
     ]
    }
   ],
   "source": [
    "'''Helper functions, for gradients, oracles, etc'''\n",
    "def grad_KWSA(F, x, c, d):\n",
    "    grad = 0\n",
    "    e = np.zeros(d)\n",
    "    for i in range(d):\n",
    "        e[i] = 1 #cb-vector\n",
    "        grad += ((F(x + c*e) - F(x))/c)*e #calculate the gradient\n",
    "        e[i] = 0 #reset cb-vector\n",
    "    return grad\n",
    "\n",
    "def grad_RDSA(F, x, c, d):\n",
    "    z = np.random.normal(0, 1, size=(d)) #mean = 0, std = 1\n",
    "    grad = ((F(x + c*z) - F(x))/c)*z\n",
    "    return grad\n",
    "\n",
    "def grad_IRDSA(F, x, c, d, m=5):\n",
    "    grad = 0\n",
    "    for i in range(m):\n",
    "        z = np.random.normal(0, 1, size=(d)) #mean = 0, std = 1\n",
    "        grad += ((F(x + c*z) - F(x))/c)*z\n",
    "    return grad/m\n",
    "\n",
    "def linear_program_oracle(coef, A, b, bounds):\n",
    "    '''\n",
    "    f(x) = c^Tx\n",
    "    Ax <= b\n",
    "    x within bounds \n",
    "    coef = [c_x0, c_x1, ....] coefficient of the equation\n",
    "    A = [[a0_x0, a0_x1, ...],[a1_x0, a1_x1, ...]] ineq constraint matrix\n",
    "    b = [b0, b1, ....] ineq constraint vector\n",
    "    bounds = [(lb_x0, ub_x0), (lb_x1, ub_x1),....]\n",
    "    '''\n",
    "    res = linprog(coef, A_ub=A, b_ub=b, bounds=bounds)\n",
    "    return res[\"x\"] \n",
    "\n",
    "# gradient test:\n",
    "'''\n",
    "f = lambda x: x[0]**2 + x[1]**2\n",
    "c = 1e-10\n",
    "x = np.array([1,2])\n",
    "'''\n",
    "f = lambda x: x[0]**4 - 32*x[0] + x[1]**2 - 8*x[1]\n",
    "c = 1e-10\n",
    "x = np.array([0,0]) #x = (2,4) is the global minimum, hence gradient = 0\n",
    "print(\"KWSA\", grad_KWSA(f, x, c, len(x)))\n",
    "print(\"RDSA\", grad_RDSA(f, x, c, len(x)))\n",
    "print(\"IRDSA\", grad_IRDSA(f, x, c, len(x)))\n",
    "x = np.array([2,4]) #x = (2,4) is the global minimum, hence gradient = 0\n",
    "print(\"KWSA\", grad_KWSA(f, x, c, len(x)))\n",
    "print(\"RDSA\", grad_RDSA(f, x, c, len(x)))\n",
    "print(\"IRDSA\", grad_IRDSA(f, x, c, len(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Franke Wolfe Algorithm and its variants from [Sahu et al] paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Standard frank wolfe algorfithm'''\n",
    "def frank_wolfe(F, x, LPO_var, alpha=0.1, max_iter=200):\n",
    "    '''\n",
    "    F = f(x)\n",
    "    x = input vector or init starting point\n",
    "    LPO_var = {A, b, bounds}, the constraints and bounds\n",
    "    '''\n",
    "    A = LPO_var[\"A\"]; b = LPO_var[\"b\"]; bounds = LPO_var[\"bounds\"]\n",
    "    dim = len(x)\n",
    "    for i in range(max_iter):\n",
    "        grad = grad_KWSA(F, x, 1e-10, dim)\n",
    "        v = linear_program_oracle(grad, A, b, bounds)\n",
    "        x += alpha*(v - x)\n",
    "    return x\n",
    "\n",
    "def frank_wolfe_away(F, x, LPO_var, alpha=0.1, max_iter=200):\n",
    "    '''\n",
    "    away version of Frank Wolfe Algorithm\n",
    "    F = f(x)\n",
    "    x = input vector or init starting point\n",
    "    LPO_var = {A, b, bounds}, the constraints and bounds\n",
    "    '''\n",
    "    A = LPO_var[\"A\"]; b = LPO_var[\"b\"]; bounds = LPO_var[\"bounds\"]\n",
    "    alpha_bar = 0 #placeholder\n",
    "    for i in range(max_iter):\n",
    "        grad = grad_KWSA(F, x, 1e-10, dim)\n",
    "        v_FW = linear_program_oracle(grad, A, b, bounds)\n",
    "        v_AS = linear_program_oracle(-grad, A, b, bounds) #away step\n",
    "        d_FW = v_FW - x; d_AS = x - v_AS\n",
    "        grad_FW = np.dot(grad, d_FW); grad_AS = np.dot(grad, d_AS)\n",
    "        if grad_FW <= grad_AS:\n",
    "            d = d_FW\n",
    "            alpha_bar = 1\n",
    "        else:\n",
    "            d = d_AS\n",
    "            #alpha_bar = #beta = ?\n",
    "        x += alpha*d\n",
    "    return x\n",
    "    \n",
    "    \n",
    "'''Zeroth Order Frank Wolfe Algorithms [Sahu et al]'''\n",
    "'''Stochastic Gradient Free Frank Wolfe - Convex'''\n",
    "def SGF_frank_wolfe_cvx(F, x, LPO_var, max_iter=200, m=10, mode=\"KWSA\"):\n",
    "    '''\n",
    "    F = f(x)\n",
    "    x = input vector or init starting point\n",
    "    LPO_var = {A, b, bounds}, the constraints and bounds\n",
    "    '''\n",
    "    A = LPO_var[\"A\"]; b = LPO_var[\"b\"]; bounds = LPO_var[\"bounds\"]\n",
    "    dim = len(x)\n",
    "    t = np.arange(max_iter) # sequence of t = 0,1,....max_iter\n",
    "    gamma = 2/(t + 8) # initialize gamma sequences\n",
    "    # rho and c sequences:\n",
    "    rho = c = None\n",
    "    if mode == \"KWSA\":\n",
    "        rho = 4/((t+8)**(2/3))\n",
    "        c = 2/(dim**(1/2) * ((t + 8)**(1/3)))\n",
    "    elif mode == \"IRDSA\":\n",
    "        rho = 4/(((1 + (dim/m))**(1/3)) * ((t+8)**(2/3)))\n",
    "        c = 2*np.sqrt(m)/(dim**(3/2) * (t+8)**(1/3))\n",
    "    elif mode == \"RDSA\":\n",
    "        rho = 4/(dim**(1/3) * (t+8)**(2/3))\n",
    "        c = 2/(dim**(3/2) * (t+8)**(1/3))\n",
    "    d = np.zeros(dim) #initial value d_0 = 0\n",
    "    x_mean = 0 #for xT\n",
    "    for i in t: #loop\n",
    "        grad = 0 #placeholder\n",
    "        if mode == \"KWSA\":\n",
    "            grad = grad_KWSA(F, x, c[i], dim)\n",
    "        elif mode == \"IRDSA\":\n",
    "            grad = grad_IRDSA(F, x, c[i], dim, m)\n",
    "        elif mode == \"RDSA\":\n",
    "            grad = grad_RDSA(F, x, c[i], dim)\n",
    "        d = (1-rho[i])*d + rho[i]*grad #used for linear programming oracle (LPO)\n",
    "        v = linear_program_oracle(d, A, b, bounds) ### LPO\n",
    "        x = (1-gamma[i])*x + gamma[i]*v\n",
    "        x_mean += x\n",
    "    x_mean /= max_iter #(sum of x)/T\n",
    "    return x_mean\n",
    "\n",
    "'''Stochastic Gradient Free Frank Wolfe - NonConvex'''\n",
    "def SGF_frank_wolfe_noncvx(F, x, LPO_var, max_iter=200, m=10):\n",
    "    '''\n",
    "    F = f(x)\n",
    "    x = input vector or init starting point\n",
    "    LPO_var = {A, b, bounds}, the constraints and bounds\n",
    "    '''\n",
    "    A = LPO_var[\"A\"]; b = LPO_var[\"b\"]; bounds = LPO_var[\"bounds\"]\n",
    "    dim = len(x)\n",
    "    t = np.arange(max_iter) # sequence of t = 0,1,....max_iter\n",
    "    gamma = 1/(max_iter**(3/4)) # initialize gamma sequences\n",
    "    # rho and c sequences:\n",
    "    rho = 4/((1+dim/m)**(1/3) * (t+8)**(2/3))\n",
    "    c = 2*np.sqrt(m)/(dim**(3/2) * (t+8)**(1/3))\n",
    "    d = np.zeros(dim) #initial value d_0 = 0\n",
    "    for i in t: #loop\n",
    "        grad = grad_IRDSA(F, x, c[i], dim, m)\n",
    "        d = (1-rho[i])*d + rho[i]*grad #used for linear programming oracle (LPO)\n",
    "        v = linear_program_oracle(d, A, b, bounds) ### LPO\n",
    "        x = (1-gamma)*x + gamma*v\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Ground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{min x, F(x)} of Standard Frank Wolfe = [ 0.05263158 -0.05263158  0.05263158] 0.008310249311776426\n",
      "{min x, F(x)} of SGF Cvx Frank Wolfe = [-0.00427155 -0.03350623 -0.00794305] 0.0012040055108330072\n",
      "{min x, F(x)} of SGF Non-Cvx Frank Wolfe = [-0.09803268  0.06707025  0.04244738] 0.01591060406015585\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Simple function for testing\n",
    "x^2 + y^2 + z^2\n",
    "-1 <= (x,y,z) <= 1\n",
    "minimizer value F(0,0,0) = 0\n",
    "'''\n",
    "f = lambda x: np.sum(x**2)\n",
    "x = np.array([1., -1., 1.]) #random x0 within feasible reigon\n",
    "A = None\n",
    "b = None\n",
    "bounds = [(-1, 1)]*len(x)\n",
    "LPO_var = {\"A\":A, \"b\":b, \"bounds\":bounds}\n",
    "m=3 #for IRDSA gradient\n",
    "x_out = frank_wolfe(f, x, LPO_var, max_iter=200)\n",
    "print(\"{min x, F(x)} of Standard Frank Wolfe =\", x_out, f(x_out))\n",
    "x_out = SGF_frank_wolfe_cvx(f, x, LPO_var, max_iter=200, m=m, mode=\"IRDSA\") #looks like m corresponds to the dimension size of the problem to be more accurate\n",
    "print(\"{min x, F(x)} of SGF Cvx Frank Wolfe =\", x_out, f(x_out))\n",
    "x_out = SGF_frank_wolfe_noncvx(f, x, LPO_var, max_iter=200, m=m)\n",
    "print(\"{min x, F(x)} of SGF Non-Cvx Frank Wolfe =\", x_out, f(x_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{min x, F(x)} of Standard Frank Wolfe = [1. 1. 1.] 2.9999999957669528\n",
      "{min x, F(x)} of SGF Cvx Frank Wolfe = [0.98077295 1.         0.98096618] 2.9242102264885914\n",
      "{min x, F(x)} of SGF Non-Cvx Frank Wolfe = [1.         1.         0.99735164] 2.994710290166227\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Maximization test, f = -F\n",
    "F(x,y,z) = x^2 + y^2 + z^2\n",
    "-1 <= (x,y,z) <= 1\n",
    "the combinations of {-1,1} x N^3 are the max values, e.g: F(-1,1,1) = -3, f = -F = 3\n",
    "'''\n",
    "f = lambda x: -np.sum(x**2)\n",
    "x = np.array([0., 0., 0.]) #random x0 within feasible reigon\n",
    "A = None\n",
    "b = None\n",
    "bounds = [(-1, 1)]*len(x)\n",
    "LPO_var = {\"A\":A, \"b\":b, \"bounds\":bounds}\n",
    "m=3 #for IRDSA gradient\n",
    "x_out = frank_wolfe(f, x, LPO_var, max_iter=200)\n",
    "print(\"{min x, F(x)} of Standard Frank Wolfe =\", x_out, -f(x_out))\n",
    "x_out = SGF_frank_wolfe_cvx(f, x, LPO_var, max_iter=200, m=m, mode=\"IRDSA\") #looks like m corresponds to the dimension size of the problem to be more accurate\n",
    "print(\"{min x, F(x)} of SGF Cvx Frank Wolfe =\", x_out, -f(x_out))\n",
    "x_out = SGF_frank_wolfe_noncvx(f, x, LPO_var, max_iter=200, m=m)\n",
    "print(\"{min x, F(x)} of SGF Non-Cvx Frank Wolfe =\", x_out, -f(x_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{min x, F(x)} of Standard Frank Wolfe = [1.58249755 2.25250736] -57.31468004107219\n",
      "{min x, F(x)} of SGF Cvx Frank Wolfe = [1.48654582 2.54036253] -56.555627058762326\n",
      "{min x, F(x)} of SGF Non-Cvx Frank Wolfe = [1.63227806 2.10316581] -57.53625480696721\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Function from: http://www.math.udel.edu/~angell/Opt/FW.pdf\n",
    "minimzer value F(1,695, 1,914) = -57.63\n",
    "'''\n",
    "f = lambda x: x[0]**4 - 32*x[0] + x[1]**2 - 8*x[1]\n",
    "x = np.array([0., 0.])\n",
    "A = [[1, -1], [3, 1]]\n",
    "b = [1, 7]\n",
    "bounds = [(0, None), (0, None)]\n",
    "LPO_var = {\"A\":A, \"b\":b, \"bounds\":bounds}\n",
    "m=5 #for IRDSA gradient\n",
    "x_out = frank_wolfe(f, x, LPO_var)\n",
    "print(\"{min x, F(x)} of Standard Frank Wolfe =\", x_out, f(x_out))\n",
    "x_out = SGF_frank_wolfe_cvx(f, x, LPO_var, max_iter=200, m=m, mode=\"IRDSA\") #looks like m corresponds to the dimension size of the problem to be more accurate\n",
    "print(\"{min x, F(x)} of SGF Cvx Frank Wolfe =\", x_out, f(x_out))\n",
    "x_out = SGF_frank_wolfe_noncvx(f, x, LPO_var, max_iter=200, m=m)\n",
    "print(\"{min x, F(x)} of SGF Non-Cvx Frank Wolfe =\", x_out, f(x_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal value is -15.220912605552863\n",
      "A solution x is\n",
      "[-1.10133381 -0.16360111 -0.89734939  0.03216603  0.6069123  -1.12687348\n",
      "  1.12967856  0.88176638  0.49075229  0.8984822 ]\n",
      "A dual solution is\n",
      "[6.98805172e-10 6.11756416e-01 5.28171747e-01 1.07296862e+00\n",
      " 3.93759300e-09 2.30153870e+00 4.25704434e-10 7.61206896e-01\n",
      " 8.36906030e-09 2.49370377e-01 1.30187120e-09 2.06014070e+00\n",
      " 3.22417207e-01 3.84054343e-01 1.59493839e-09]\n"
     ]
    }
   ],
   "source": [
    "import cvxpy as cp\n",
    "# Generate a random non-trivial linear program.\n",
    "m = 15\n",
    "n = 10\n",
    "np.random.seed(1)\n",
    "s0 = np.random.randn(m)\n",
    "lamb0 = np.maximum(-s0, 0)\n",
    "s0 = np.maximum(s0, 0)\n",
    "x0 = np.random.randn(n)\n",
    "A = np.random.randn(m, n)\n",
    "b = A @ x0 + s0\n",
    "c = -A.T @ lamb0\n",
    "\n",
    "# Define and solve the CVXPY problem.\n",
    "x = cp.Variable(n)\n",
    "prob = cp.Problem(cp.Minimize(c.T@x),\n",
    "                 [A @ x <= b])\n",
    "prob.solve()\n",
    "\n",
    "# Print result.\n",
    "print(\"\\nThe optimal value is\", prob.value)\n",
    "print(\"A solution x is\")\n",
    "print(x.value)\n",
    "print(\"A dual solution is\")\n",
    "print(prob.constraints[0].dual_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
